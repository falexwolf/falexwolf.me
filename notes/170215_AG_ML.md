# AG Maschinelles Lernen

Im Folgenden skizziere ich verschiedene mögliche Zugänge zum Thema. Es wird ein Bezug zur Gentechnologie (*Genome Editing*) entwickelt (*Künstliche Intelligenz* und *Künstliches Leben*), der sich in weiten Teilen natürlich ergibt, den ich hier aber freilich auch auf Grund meiner eigenen Arbeit an dieser Schnittstelle anbringe.

## Ausgangslage

* Eine kleine Gruppe von Menschen versteht und entwickelt Technologien, die einen starken Einfluss auf die Lebenswelt aller haben werden, wie bereits häufig in der Geschichte der Zivilisation.
* Um negative Auswirkungen und Missbrauch zu verhindern, müssen diese Technologien möglichst frei zugänglich sein und deren Entwicklungsprozess von der Öffentlichkeit/ Politik, wenn möglich, gesteuert werden.
* Es bestehen bereits Institutionen: *Future of Humanity Institute, U Oxford*, *Berkeley ML Intelligence Institute*, *OpenAI*, ..., allerdings keine in Deutschland.
* Hauptprotagonist ist eine *technologiegläubige* Technikelite.

Nun ist in der Öffentlichkeit hauptsächlich folgendes Thema präsent.   

## Die dramatisierten existenziellen Gefahren des Maschinellen Lernens und der Gentechnologie

* Das *Future of Humanity Institute, U Oxford* erhebt das Maschinelle Lernen zur größten existenziellen Bedrohung der Menschheit im nächsten Jahrhundert, neben dem Klimawandel und dessen Folgen. Medien, Elon Musk und andere sagen Ähnliches.
* Meiner Einschätzung nach sind konkrete *existenzielle Gefahren*, soweit es bisher abzusehen ist, gering. Bisher sind nur Fälle von *weak Artificial Intelligence* bekannt. Das Beispiel Atari, das Stanford-Professor Stuart Russell auf dem vergangenen World Economic Forum bringt und von dem er behauptet, es würde zum ersten Mal den Bereich der *weak AI* zur *strong AI* hin verlassen, ist klar immer noch *weak AI*. Und im Falle der Gentechnologie: Im Prinzip ist es denkbar, dass genetisch veränderte Viren oder Bakterien ein Labor verlassen könnten, es werden dazu aber *einfach* ähnliche Überlegungen angestellt, wie zur Gefahr nuklearer Unfälle.

Ein deutlich vielschichtigeres Problem in dieser Diskussion ist dagegen die Frage nach unserem Selbstverständnis angesichts *künstlichen Lebens* (KL) und *künstlicher Intelligenz* (KI).

## Das Selbstverständnis des Menschen angesichts von ML und Gentechnologie

* KL besitzt die gleiche Würde wie natürlich entstehendes Leben. Man kann hier viele Standpunkte vertreten, inwiefern Forschung zu KL unterbunden werden soll (angefangen bei Organoiden, die wohl die wenigsten nicht akzeptieren), aber das soll hier nicht der Schwerpunkt sein.
* Vielmehr: Nach bestimmten Kriterien generiertes KL, genauso wie KI, wird Eigenschaften natürlich geschaffener Menschen in Frage stellen. Diese Eigenschaften sind, soweit es abzusehen ist, *oberflächliche Eigenschaften*, formale Intelligenz auf eng definierten Problemen, *Aussehen*, Krankheitsresistenz usw., und damit alles Eigenschaften, in die auch heute schon massiv eingegriffen wird (mit besserer Bildung und Medizin für wohlhabende Schichten, beispielsweise). Auch hier halte ich es für unwahrscheinlich, dass unser Menschsein (beispielsweise in Abgrenzung zum Tiersein), herausgefordert wird. Empathie, Kreativität, Liebe, Verantwortung, Intuition, könnte nur von KI gelernt werden, die bereits menschlich interagieren kann. Nur dann kann eine Maschine menschliche Reaktionen auf ihr Verhalten erwarten, und es läßt sich eine Kostenfunktion (innerhalb von *Reinforcement Learning*) aufstellen, die eine Maschine auf Grundlage von menschlichen Erfahrungen trainiert, *belohnt* und *bestraft*. Nur dann kann auch *menschliches Verhalten* gelernt werden. Trotzdem gibt es enorme Schwierigkeiten: a) man müsste die *Kosten* in der Kostenfunktion quantifizieren, also zum Beispiel das Zurückweisungsgefühl, das Kinder bei Zurechtweisung durch die Eltern empfinden. b) Man müsste einem Lernprozess hunderttausende menschliche Interaktionen zu Grunde legen. Beides scheint illusorisch, wenn sich nicht herausstellt, dass menschliche Psychologie ein Fixpunkt in einer sich abwechselnden Simulation menschlichen Verhaltens und einer Reaktionen auf diese Simulation ist. Nur dann wird menschliches Verhalten *simulierbar*. Das scheint extrem unwahrscheinlich. Allerdings erschien auch die Nutzung nuklearer Energie um 1930 noch extrem unwahrscheinlich.

Auch hier haben wir also keinen enormen Diskussionbedarf und wir können uns folgendem Thema zuwenden. 
 
## Grundsätzliche Veränderungen unserer Lebenswelt durch ML und Gentechnologie

* Für weite Teile der Gesellschaft sind die genannten oberflächlichen, harten Eigenschaften, ein wichtiger Bestandteil ihres Selbstverständnis, auch wenn ich sie nicht fundamental zum Menschsein rechnen würde.
* Ein Taxifahrer, dessen Existenz durch Uber bedroht wird (jüngster durch Digitalisierung verursachter Umbruch auf dem Arbeitsmarkt), oder ein *Datensichter*, der seinen Job durch ML verliert (die Berufssparte, die ML als erstes überflüssig machen wird). ML ist hier ein weiterer Schritt in der seit über 100 Jahren wachsenden Automatisierung.
* Für mich ist also die bei weitem größte praktisch relevante Frage: wie kann man Menschen, deren Alltagsaufgabe überflüssig wird, eine neue, sie erfüllende, sinnvolle Aufgabe geben. Wie sieht eine Gesellschaft aus, die von genetisch veränderten (krankheitsresistenten, womöglich gut aussehenden, klugen) Menschen geprägt ist - kann und will man eine solche Gesellschaft verhindern? Der sich eröffnende Fragenkanon ist keinesfalls nur generisch mit ML oder Gentechnologie verknüpft, sondern zum großen Teil genauso alt wie die Geschichte der Menschheit. Dennoch werden wir diese Fragen in den nächsten Jahrzehnten auf eine andere Art und Weise stellen.
* Freilich ist das Thema so zu breit und muss eingegrenzt werden. Dazu mehr in Zukunft.

Es gibt nun eine Vielzahl von Bezügen zu bestehenden Themen.

## Bezüge zu bestehenden Themen

* klassischer Kanon bioethischer Fragen
* Datenschutz, Datensicherheit, Big Data
* Ökonomie der Ideen gegen Ökonomie des Kapitals
* kulturelle Umbrüche in der Geschichte der Zivilisation, je nach Schwerpunkt ab dem Buchdruck, der Industrialisierung, Automatisierung, Digitalisierung...
* Technikelite versus Rest der Wissenschaften und Humanistisches Bildungsideal, bzw. den Schwerpunkt etwas anders setzend: kritische Beleuchtung von Technologie/ Naturwissenschaft als positivistischer Ideologie im Gegensatz, beispielsweise, zu Religion, oder einem humanistischen Wissenschaftsverständnis
* usw.


## Resources

#### From BBC http://www.bbc.com/news/technology-37713629

Another speaker at the event was Professor Maggie Boden, a major figure in artificial intelligence research for more than 50 years.

She told me she had long seen the need for the debate we are having now - but she was not worrying about our imminent extinction and was rather less convinced than Professor Hawking that we were heading into the AI future at breakneck speed.

Her concern was about the impact of automation right now - in Japan at least - on elderly people. She pointed to the enthusiasm for the use of robots in the care of the elderly and sick and said society would have to ask whether this was dehumanising. "I'm scared of that," she said.

After decades of research into AI, Professor Boden still does not see robots replacing humans in functions which require empathy and emotional intelligence. Artificial intelligence could soon offer governments the chance to cut growing bills for social care - but at a cost for those in need of help.

Just one of the issues which will now be addressed by the Centre for the Future of Intelligence - and rather more urgent than the threat from some future Terminator. 



